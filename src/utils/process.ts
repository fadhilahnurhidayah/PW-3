export const processes = [
  {
    title: "Data Collection",
    description:
      "The first step in any data science project is gathering data from various sources such as APIs, databases, or web scraping. This phase involves identifying the relevant data required for analysis and ensuring data quality through validation and cleaning processes.",
  },
  {
    title: "Data Cleaning",
    description:
      "Once the data is collected, it needs to be cleaned and pre-processed. This includes handling missing values, removing duplicates, and transforming the data into a suitable format for further analysis.",
  },
  {
    title: "Exploratory Data Analysis",
    description:
      "Exploratory Data Analysis (EDA) is a critical step where statistical techniques and visualizations are used to understand the data’s structure, patterns, and relationships. This helps in forming hypotheses and selecting appropriate modeling techniques.",
  },
  {
    title: "Model Building",
    description:
      "In this stage, machine learning algorithms are applied to the prepared data to build predictive models. Various models are tested and evaluated using metrics like accuracy, precision, and recall to select the best performing model.",
  },
  {
    title: "Model Evaluation & Tuning",
    description:
      "Once a model is selected, it is further optimized through hyperparameter tuning and cross-validation techniques to improve its performance and ensure generalization on unseen data.",
  },
  {
    title: "Deployment",
    description:
      "After the model meets performance requirements, it is deployed into a production environment. This phase includes setting up APIs, integrating with applications, and monitoring the model’s performance over time.",
  },
  {
    title: "Maintenance & Updates",
    description:
      "The final step is to continuously monitor the model's performance and update it as needed to ensure accuracy and efficiency as new data becomes available.",
  },
];